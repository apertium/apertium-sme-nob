\newcommand{\comment}[1]{\textbf{TODO:~#1}}
\renewcommand{\comment}[1]{} % uncomment for final version

% TODO:
%\usepackage[utf8x]{inputenc}

\newcommand{\href}[2]{{\tt #1}} % put hyperref in preamble? TODO

\newcommand{\sme}{{\tt sme}}
\newcommand{\nob}{{\tt nob}}
\newcommand{\smenob}{\sme$\rightarrow{}$\nob}
\newcommand{\nobsme}{\nob$\rightarrow{}$\sme}

\achapter{Evaluating North S\'{a}mi to Norwegian assimilation RBMT}{N.N. and N.N.}

% testen:
% a. teste ut 10x10x10
% b. evaluere 

% skrivinga:
% - leite etter litteratur om evaluering av system for å forstå tekst
% - skrive rammetekst, lage dummy-tabellar for testresultat
% - så, når testinga er ferdig, fylle inn resultat, skrive ferdig, 

% disposisjon
% - intro: mål og plan for artikkelen
% - samisk, gisting, tidlegare litteratur
% - vår test, vår analyse
% - oppsummering og konklusjon, evaluering av kva som er potensiale for forbetring


  
    % \begin{abstract}
We describe the development and evaluation of a rule-based machine
translation assimilation system from Northern S\'{a}mi to Norwegian Bokm{\aa}l,
built on a combination of Free and Open Source (FOSS) resources: the
Apertium platform and the Giellatekno HFST lexicon and Constraint
Grammar disambiguator.

We detail the integration of these and other resources in the system
along with the construction of the lexical and structural transfer,
and evaluate the translation quality using various methods. Finally,
some future work is suggested.
    % \end{abstract}




\section{Introduction} % and roadmap
This paper describes and evaluates a rule-based machine translation
system from Northern S\'{a}mi to Norwegian Bokm{\aa}l, re-using several
existing free and open source resources. 

We begin with an introduction to the languages and the technology
used, followed by a description of how the system was developed. Then
we evaluate the system with respect to the assimilation purpose, and
discuss the results and ideas for improvements.

\subsection{The Languages}
Northern S\'{a}mi (\sme{}) is a Finno-Ugric language spoken by between
15,000 and 25,000 people in the northern parts of Norway, Sweden and
Finland. Norwegian Bokm{\aa}l (\nob{}) is a North Germanic language with
about 4.5 speakers, mostly in Norway. Northern S\'{a}mi is a highly
inflected, agglutinative language, whereas Norwegian morphology is
comparatively simple.

Most \sme{} speakers in Norway understand \nob{}, while most \nob{}
speakers do not understand \sme{}. The languages are completely
unrelated, and the linguistic distance is great, making it hard to
achieve high quality MT results. A \nobsme{} system would only be useful if the
quality were good enough that it could be used for text production
(post-editing). On the other hand, a \smenob{} gisting-quality system
can be useful for the large group of \nob{} speakers who don't
understand \sme{}. Thus we chose to focus on the \smenob{} direction
first.

We do not know of other machine translation (MT) systems between \sme{}
and any Indo-European language, although \citet{tyers2009dpm} describe
a prototype system between Northern S\'{a}mi and Lule S\'{a}mi.



\section{Design}
 \label{sec:design}

\subsection{The Apertium Pipeline}
This language pair is based on the Apertium MT
platform\citep{forcada2011afp}. Apertium provides a highly modular,
shallow-transfer pipeline MT engine, as well as data for language
pairs. Both the engine and the data for all language pairs (about 30
released pairs as of now) are licensed under the
GPL\footnote{\href{http://www.fsf.org/licensing/licenses/gpl.html}{http://www.fsf.org/licensing/licenses/gpl.html}}.

Apertium language pairs are defined by Unix pipelines, where the
typical pipeline consists of:

\begin{itemize}
\item deformatting (hiding format information or markup from the
  engine),
\item source language morphological analysis with a finite state
  transducer (FST),
\item disambiguation using a Hidden Markov Model (HMM) and/or
  Constraint Grammar (CG), 
\item lexical transfer (word-translation on the disambiguated source),
\item one and one or more levels of structural transfer
  (ie.~reordering and changes to morphological features), 
\item target-language generation with an FST
\item reformatting (letting format information be shown again)
\end{itemize}

Most Apertium language pairs use the lttoolbox FST package for
analysis and generation. The lttoolbox dictionaries are written in
XML, where one dictionary may be compiled both to an analyser and a
generator. The \smenob{} pair uses lttoolbox for \nob{} generation and
the transfer lexicon, while the \sme{} analyser is written in the
Xerox lexc/twol formats\citep{beesley2003fsm}. Both systems allow
generalising over classes using paradigms/continuation lexicons, but
differ in other features. We use the FOSS package Helsinki Finite
State Tools, HFST \citep{linden2011hfst} to compile and run the
analyser (see section \ref{sec:hfst}).

The morphological analysis gives us ambiguous output with no syntactic
information. For morphological (e.g.~part-of-speech) disambiguation,
syntactic annotation/disambiguation and lexical
selection\footnote{Similar to Word Sense Disambiguation, but
  restricted to senses that have differing translations.}, we use
Constraint Grammar \citep{karlsson1990cgf}\footnote{Using the FOSS
  package {\tt \small VISL CG-3},
  \href{http://beta.visl.sdu.dk/cg3.html}{http://beta.visl.sdu.dk/cg3.html}}.
Morphological disambiguation and syntactic annotation/disambiguation
are run as one CG module, the output of which is unambiguous both
morphologically (one analysis per form) and syntactically (each
form/analysis is annotated with one syntactic tag).

The first CG module is directly followed by a lexical selection CG
module\footnote{If the disambiguation rules leaves any ambiguity, that
  module is configured only print the first analysis. We may later
  train an HMM to get rid of leftover ambiguity, this would go between
  the two CG modules.}, which may add subscripts to lemmas in certain
contexts in order to select a different lexical translation. 

Lexical selection is followed by pretransfer (minor format changes in
preparation of transfer) and then a four-stage finite-state-based
chunking transfer. The first stage handles lexical transfer as well as
chunking based on patterns of morphological and syntactic tags
(further detail in section \ref{sec:structural-transfer}).

Output from the transfer module is fed to morphological generation
with the lttoolbox-based \nob{} generator. De-/reformatters applied to
the beginning and end of the pipeline let us preserve formatting of
various document types.

\subsection{HFST}
\label{sec:hfst}
One novel feature of apertium-sme-nob is the HFST-based analyser. HFST
makes it possible to compile lexicons and morphologies originally
written for the closed-source Xerox Finite State Tools using only free
and open source tools, and run them with Apertium-compatible output
formats. As with most Xerox-based analysers, the \sme{} lexicon and
morphology are written in \textbf{lexc} and compiled into an FST, onto
which \textbf{twol} rules are composed which define the
morphophonology. HFST analysers are slower at compiling and processing
than lttoolbox, but certain morphological phenomena, especially
non-concatenative phenomena (e.g. \sme{} consonant gradation) are
impossible---or at least very difficult---to describe in lttoolbox.
Since Northern S\'{a}mi is quite morphologically complex, a purely
lttoolbox-based analyser would be difficult to maintain.


\section{Development}
  \label{sec:development}

This section describes how the language pair was developed.
\subsection{Resources}
We re-used several FOSS resources in creating this language pair. The
\nob{} generator came from {\tt
  apertium-nn-nb}\citep{unhammer2009rfr}, while most of the \sme{}
resources came from the Divvun and Giellatekno S\'{a}mi language
technology projects \footnote{See
  \href{http://divvun.no}{http://divvun.no} and
  \href{http://giellatekno.uit.no}{http://giellatekno.uit.no}.},
including the lexicon/morphology and disambiguator/syntactic
annotation CG. These were continually updated as the ``upstream''
versions changed.

The lexical selection CG and the transfer rules were written from
scratch. The translation lexicon was originally based on various
word-lists from Giellatekno
\href{http://giellatekno.uit.no}{http://giellatekno.uit.no}
\comment{was Vuosttaš Digis\'{a}nit used?}, but expanded throughout
development.
\subsection{Analysis and derivational morphology}
The morphological analyser from N.N.\comment{Giellatekno} was not
originally made with machine translation in mind, and we had to make
several modifications, from using the Apertium tag format, to
restricting derivational morphology and removing root forms without
translations. The modifications in the language pair are all done
automatically using scripts, so that we can keep the analyser
up-to-date with the upstream version.

The upstream analyser contains many lemmas that are not in our
translational dictionary. Since these often lead to transfer errors
that can affect the surrounding context, and can suppress the choice
of forms that \textit{have} translations, we ``trim'' the analyser
down to those forms which are in the translational dictionary. To do
this, we use a script which analyses the lexc source files with the
translational dictionary, and outputs only those entries which have
translational analyses. The untrimmed source files weigh in at about
3.5 MB, trimming this down to 2.6 MB is done by a script which runs in
<10 seconds.

The original analyser defines quite a lot of rules for derivational
processes. Allowing for derivational morphology expands the coverage
of the analyser without having to add new root forms (lexicalisation),
but also makes transfer much harder to deal with, as well as most of
the time giving very odd-sounding translations.

To give an example of the latter, `geafivuohta' is an
adjective$\rightarrow{}$noun derivation of `geafi', meaning `poor'.
Simply carrying over the information that this is an
adjective$\rightarrow{}$noun derivation into the target language
dictionary (if that dictionary also defined derivational processes)
could give us forms that sound like `poorness' or `poority' or
`poordom', whereas giving `geafivuohta' status as a real root form
would let us specify that `geafivuohta' should translate to `poverty'.
Without derivations, `geafivuohta' would either be lexicalised and
translated to `poverty', or not translated at all.

Derivations also create extra transfer complexity. A causative verb
derivation requires transfer rules that turn the causative verb into a
periphrastic construction (e.g. `let NP VERB'). If a derivation
changes the part-of-speech from verb to noun, we have to translate the
derivation into a certain verb form that looks right in a noun context
(e.g.~present tense of \nob verbs will most of the time look like an
actor noun)\footnote{The alternative would be to define, for each \sme{}
  verb, both a noun and a verb translation on the \nob side of the
  translational dictionary, but this takes away the whole point of
  increasing coverage without adding all the root forms.}. To make
this even more complex, even a lexicalised form might require a
part-of-speech change in the transfer lexicon if there is no word with
the same meaning and part-of-speech in the target language; in that
case, we also have to ensure transfer works for all possible
derivations of all possible defined part-of-speech changes.

However, since \smenob{} is meant for gisting, where an odd-sounding
translation is more useful than an untranslated word, and resources
for automatically expanding the bilingual dictionary are scarce, we
decided to allow certain derivations. We define legal derivations by
the use of additional twol rules which simply forbid analyses
containing certain tags or tag sequences. These twol rules are
composed onto the main analyser in Apertium, but not used upstream.

\subsection{Disambiguation}
The CG created by Giellatekno was usable in Apertium with only minor
changes to tag naming, requiring very little manual intervention to
keep up-to-date. However, we did add Apertium-only rules which remove
derivations and compound readings if there are lexicalised readings
available, since we want lexically specified translations to override
the guesswork done by derivation transfer.

\subsection{Lexical selection}
A lexical selection CG was created in order to select between
different possible translations that otherwise share the same
part-of-speech information. Currently it has only 102 rules covering
52 lemmas, mostly high-frequency ones, although 802 lemmas of the
transfer lexicon have at least one alternative translation.

\subsection{Lexical transfer}
The open classes of the transfer lexicon were initiated with entries
from the 9900 lemma dictionary Vuosttaš Digis\'{a}nit\footnote{GPL and CC,
  see
  \href{http://giellatekno.uit.no/words/dicts/index.eng.html}{http://giellatekno.uit.no/words/dicts/index.eng.html}.},
although many multiword translations had to be removed or simplified;
later on, entries were mostly added manually. Not including lexical
selection alternatives, there are currently about 3300 verbs, 1400
adjectives and 14000 nouns in the transfer lexicon.

Unlike with most Apertium language pairs, we did not make an attempt
to change the tag set in the analyser to conform with the Apertium
standard (apart from minor format differences). The change from e.g.
\texttt{<N><Prop>} (proper noun) to \texttt{<np>} or \texttt{<Sg1>} to
\texttt{<sg><p1>} happens in the transfer lexicon, mostly using a
\textbf{paradigm} definition to generalise over changes for each part
of speech. Part of the derivation handling also happens here, e.g. the
most passive derivations turn into plain passive forms, while verbs
derived into actor-nouns are transferred to present tense verbs.

We also add tags which are used only as a signal to transfer, which
are removed before generation. The causative derivation of a form gets
a tag which makes transfer form a periphrastic `let'-construction, but
we also add the same tag to all forms if the root itself is a
lexicalised causative (similarly with lexicalised passives). Verbs are
tagged according to the most likely animacy of the agent.

\subsection{Structural transfer}
\label{sec:structural-transfer}
Structural transfer is divided into four stages, with different
responsibilities:

\begin{enumerate}

\item Chunking: noun phrases turn into larger chunks, prepositions are
  output based on case information, verb auxiliaries and adverbs are
  output based on verb modality, voice and derivation tags.

\item Interchunk1: simple anaphora resolution (most recent subject
  gender), merging coordinated noun phrase chunks, moving
  postpositions before noun phrases.

\item Interchunk2: major word order changes, inserting dropped
  pronouns, inserting adverbs to indicate verb modality, correcting
  noun phrase definiteness using verb information.

\item Postchunk: inserting articles/determiners and the infinitive
  marker, tag cleanup in preparation of generation.
\end{enumerate}


\subsection{Generation}
The generator was re-used from the language pair
\texttt{apertium-nn-nb} with almost no changes apart from some root
form additions to the lexicon, and marking of adjectives as synthetic
or analytic (which might later be used to improve
\texttt{apertium-nn-nb}).

\section{Evaluation}
\label{sec:eval}
The naïve coverage\footnote{A form is counted as covered if it gets at
  least one analysis. It might have ambiguity which the analyser does
  not cover, thus `naïve'.} of the analyser is shown in table
\ref{table:cov} for legal text (laws), the \sme{} Wikipedia (wiki) and
a corpus of \sme{} news articles. All forms which pass through the
analyser, will also pass through the transfer lexicon, transfer rules
and generator, so this shows the coverage of the other dictionaries
(in the \smenob{} direction) as well. Since derivations are not
specified in the translational dictionary, we show coverage with and
without derivation-only analyses counted. The table also shows the
ambiguity rate (amount of analyses per known word) with and without
derivations counted. 

The Wikipedia corpus seems to have very low coverage, but looking over
the unknown words, it seems that many of them are in Finnish, English
or Norwegian (the rest are mostly proper names).


\begin{table}
  \begin{center}
  \begin{tabular}{crrrrr}
   Corpus     & tokens   & coverage & ambig.rate  & coverage w/o deriv & ambig.rate w/o deriv \\
   laws       &  51706   & 94.68\%  & 2.65        & 86.02\%            & 2.32 \\
   wiki       & 19942    & 77.52\%  & 2.36        & 74.56\%            & 2.19 \\
   news       & 1020250  & 94.72\%  & 2.59        & 90.96\%            & 2.34 \\
  \end{tabular}
    \caption{Naïve coverage on several corpora.}
    \label{table:cov}
  \end{center}
\end{table}
In the rest of this section we evaluate the practical performance of
the system using several methods. First we do a word-error rate test,
which shows how well the system would perform in a
post-editing/dissemination setting, then a set of tests meant to find
out how well the system performs in a gisting/assimilation setting.
All tests were run on revision 37177 of \texttt{apertium-sme-nob}.



\subsection{Word Error Rate on Post-Edited text}
\label{sec:WER}
We did a Word Error Rate test on a short children's story
\footnote{\href{https://apertium.svn.sourceforge.net/svnroot/apertium/branches/xupaixkar/rasskaz}{https://apertium.svn.sourceforge.net/svnroot/apertium/branches/xupaixkar/rasskaz}}
and some paragraphs from a history web page
\footnote{\href{http://skuvla.info/skolehist/siri97-s.htm}{http://skuvla.info/skolehist/siri97-s.htm}}.
The results are shown in \ref{table:wer}\footnote{Our post-edits are
  available from our public repository.}. The translator obviously
struggles with the more complex formulations in the history text, and
has a long way to go before being useful for post-editing.


\begin{table}
  \begin{center}
  \begin{tabular}{ccrrr}
   Text       & tokens & Unknown & WER  \\
   children's & 415     & 5      & 45.96\% \\
   history    & 435     & 28     & 60.32\%  \\
  \end{tabular}
    \caption{Word error rate on two short texts.}
    \label{table:wer}
  \end{center}
\end{table}


\subsection{Gisting evaluation}
  
In order to evaluate to what extent the system was able to convey the
meaning of the original, we arranged a test containing 3 parts. All
the test were based on sentences from a parallel corpus of
non-fiction, the corpus had not been used during development of the MT
system. The first test, a multiple choice test, presented 10 sentences
drawn from the corpus. For each sentence, the test person also got the
translation, and 3 alternative paraphrases. The second test was set up
as the first, but instead of the 3 alternatives the test presented an
open question related to the translation.

The third test showed a \sme{} source sentence, then the MT output of
that sentence, followed by the reference translation (5-15 words long)
where at least two of the nouns were removed. For each removed noun,
we instead showed a randomised, clickable list consisting of the
originally removed word, along with a random choice of other
nouns\footnote{Nouns were of the same length (+- 3 characters), pulled
  from the same 55128 word long legal text, had the same morphological
  features (gender, definiteness, number) and were never ambiguous
  with verbs. This questionnaire generator is available from our
  public repository and should be usable with other translators.} and
finally a "none seem to fit" choice. The users (who did not understand
\sme{}) were instructed to click what seemed to be the removed word,
using the MT as a guide. Ten consecutive sentences from the same piece
of text were shown one at a time.

\begin{table}[htdp]
\caption{default}
\begin{center}
\begin{tabular}{lccc}
Type & Multiple & Fill-in & Random \\
Result & 77 \% & 41 \% & 75 \% \\
\end{tabular}
\end{center}
\label{eval}
\end{table}%



The results from the multiple choice and random word tests correlate with each other, whereas the fill-in test shows much worse results. The reason for that is that the fill-in test was more vulnerable to holes in the MT output. Four of the 10 test sentences got no or only one correct answers. What made these sentences so hard was that the system failed to translate the key word in the sentence.

\enumsentence[(a)]{Mun muitt\'{a}n ahte Lillemor Isaksen, geas lei gymn\'{a}sa, measta ii fidnen oahpaheaddjibarggu go son lei s\'{a}megielat.}{I remember that Lillemor Isaksen, who had secondary high school, almost did not get any work as a teacher, since she was \textbf{saami-speaking}}

\enumsentence[(b)]{Jeg husker at Lillemor Isaksen, som hadde *gymn\'{a}sa, nesten ikke han f{\aa}tt l{\ae}rerarbeidet da han var samisker.}{I remember that Lillemor Isaksen, who had secondary high school, almost did not get any work as a teacher, since she was \textbf{a saamier}.}

The word $samier$ (here interpreted as a agent noun, on a par with $snekker$ ($carpenter$) does not exist, and is interpreted by 9 of the informants as "a Saami", instead of the correct "a Saami speaker". Here the missing translation of the key word blocked a proper understanding of the sentence.


%  \eenumsentence{\item \shortex{3}
%         {kalk-n & apra & kpa-ra}
%         {sago pudding V SG-OBL & plate VII PL & big-VII PL}
%         {`big plates of sago pudding'}
% \toplabel{sago}
%  \item \shortex{1}
%         {pia-ka-tim{\'{\i}}}
%         {words O-1SG A-say}
%         {`I talked.'}
%  \item \shortex{1}
%         {na-mpu-wap{\'a}t-ncut}
%         {3SG O-3PL A-climb-RM PAST}
%         {`They climbed it (the tree).'}
%  \item \shortex{2}
%         {nan-{\'a}wkura-na & amtra}
%         {PL IMP-gather-IMP & food V PL}
%         {`Collect food!'}}


\subsection{Error analysis}


\section{Discussion and outlook}


The lexical selection CG can be automatically expanded with rules
created by the Apertium package \texttt{apertium-lex-tools}
\citep{???}.

\section*{Acknowledgements}
Development was funded by \comment{what are they called now?}
Thanks to N.N.


\nocite{zubizarreta2009amt}
