\newcommand{\comment}[1]{\textbf{TODO:~#1}}
%\renewcommand{\comment}[1]{} % uncomment for final version

% TODO:
%\usepackage[utf8x]{inputenc}

\newcommand{\href}[2]{{\tt #1}} % put hyperref in preamble? TODO

\newcommand{\sme}{{\tt sme}}
\newcommand{\nob}{{\tt nob}}
\newcommand{\smenob}{\sme$\rightarrow{}$\nob}
\newcommand{\nobsme}{\nob$\rightarrow{}$\sme}

\achapter{apertium-sme-nob:using an HFST lexicon in a long-distance RBMT system}{N.N.}
% … or this title?
% Evaluating a North Sami to Norwegian dissimilation system

% testen:
% a. teste ut 5x5x5
% b. evaluere og lage 5 til av dei ikkje-genererte (opne for fleire genererte?)
% c. verve folk til å bruke påska til dette (må vere slike som ikkje kan samisk)
% d. på eit tidspunkt setje strek

% 5x5x5
% http://baldur.dyndns.tv/~kiwibird/gist-sme-nob/fyll_inn/
% http://baldur.dyndns.tv/~kiwibird/gist-sme-nob/abc/
% http://baldur.dyndns.tv/~kiwibird/gist-sme-nob/

% skrivinga:
% - leite etter litteratur om evaluering av system for å forstå tekst
% - skrive rammetekst, lage dummy-tabellar for testresultat
% - så, når testinga er ferdig, fylle inn resultat, skrive ferdig, 

% disposisjon
% - intro: mål og plan for artikkelen
% - samisk, gisting, tidlegare litteratur
% - vår test, vår analyse
% - oppsummering og konklusjon, evaluering av kva som er potensiale for forbetring


  
    % \begin{abstract}
    We describe the development of a rule-based machine translation
    system from Northern Sámi to Norwegian Bokmål built on a
    combination of Free and Open Source (FOSS) resources: the Apertium
    platform and the Giellatekno HFST lexicon and Constraint Grammar
    disambiguator.
    \comment{more}
    We detail the integration of these and other resources in the
    system along with the construction of the lexical and structural
    transfer, and evaluate the translation quality in comparison with
    another system. Finally, some future work is suggested.
    % \end{abstract}




\section{Introduction}
This paper describes the development of a rule-based machine
translation system from Northern Sámi to Norwegian Bokmål, re-using
several existing free and open source resources. \comment{Roadmap}

\subsection{The Languages}
Northern Sámi (\sme{}) is a Finno-Ugric language spoken by between
15,000 and 25,000 people in the northern parts of Norway, Sweden and
Finland. Norwegian Bokmål (\nob{}) is a North Germanic language with
about 4.5 speakers, mostly in Norway. Northern Sámi is a highly
inflected, agglutinative language, whereas Norwegian morphology is
comparatively simple.

Most \sme{} speakers in Norway understand \nob{}, while most \nob{}
speakers do not understand \sme{}. The languages are completely
unrelated, and the linguistic distance is great, making it hard to
achieve high quality MT results. A \nobsme{} system would only be useful if the
quality were good enough that it could be used for text production
(post-editing). On the other hand, a \smenob{} gisting-quality system
can be useful for the large group of \nob{} speakers who don't
understand \sme{}. Thus we chose to focus on the \smenob{} direction
first.

We do not know of other machine translation (MT) systems between \sme
and any Indo-European language, although \citet{tyers2009dpm} describe
a prototype system between Northern Sámi and Lule Sámi.



\section{Design}
 \label{sec:design}

\subsection{The Apertium Pipeline}
This language pair is based on the Apertium MT
platform\citep{forcada2011afp}. Apertium provides a highly modular,
shallow-transfer pipeline MT engine, as well as data for language
pairs. Both the engine and the data for all language pairs (about 30
released pairs as of now) are licensed under the
GPL\footnote{\href{http://www.fsf.org/licensing/licenses/gpl.html}{http://www.fsf.org/licensing/licenses/gpl.html}}.

Apertium language pairs are defined by Unix pipelines, where the
typical pipeline consists of:

\begin{itemize}
\item deformatting (hiding format information or markup from the
  engine),
\item source language morphological analysis with a finite state
  transducer (FST),
\item disambiguation using a Hidden Markov Model (HMM) and/or
  Constraint Grammar (CG), 
\item lexical transfer (word-translation on the disambiguated source),
\item one and one or more levels of structural transfer
  (ie.~reordering and changes to morphological features), 
\item target-language generation with an FST
\item reformatting (letting format information be shown again)
\end{itemize}

Most Apertium language pairs use the lttoolbox FST package for
analysis and generation. The lttoolbox dictionaries are written in
XML, where one dictionary may be compiled both to an analyser and a
generator. The \smenob{} pair uses lttoolbox for \nob{}
generation, while the \sme{} analyser is written in the Xerox lexc/twol
format\citep{beesley2003fsm}. We use the FOSS package Helsinki Finite
State Tools, HFST \citep{linden2011hfst} to compile and run the
analyser (see section \ref{sec:hfst}).

The morphological analysis gives us ambiguous output with no syntactic
information. For morphological (e.g.~part-of-speech) disambiguation,
syntactic annotation/disambiguation and lexical
selection\footnote{Similar to Word Sense Disambiguation, but
  restricted to senses that have differing translations.}, we use
Constraint Grammar \citep{karlsson1990cgf}\footnote{Using the FOSS
  package {\tt \small VISL CG-3},
  \href{http://beta.visl.sdu.dk/cg3.html}{http://beta.visl.sdu.dk/cg3.html}}.
Morphological disambiguation and syntactic annotation/disambiguation
are run as one CG module, the output of which is unambiguous both
morphologically (one analysis per form) and syntactically (each
form/analysis is annotated with one syntactic tag).

The first CG module is directly followed by a lexical selection CG
module\footnote{If the disambiguation rules leaves any ambiguity, that
  module is configured only print the first analysis. We may later
  train an HMM to get rid of leftover ambiguity, this would go between
  the two CG modules.}, which may add subscripts to lemmas in certain
contexts in order to select a different lexical translation. 

Lexical selection is followed by pretransfer (minor format changes in
preparation of transfer) and then a four-stage finite-state-based
chunking transfer. The first stage handles lexical transfer as well as
chunking based on patterns of morphological and syntactic tags
(further detail in section \ref{sec:structural-transfer}).

Output from the transfer module is fed to morphological generation
with the lttoolbox-based \nob{} generator. De-/reformatters applied to
the beginning and end of the pipeline let us preserve formatting of
various document types.

\subsection{HFST}
\label{sec:hfst}
One novel feature of apertium-sme-nob is the HFST-based analyser. HFST
makes it possible to compile lexicons and morphologies originally
written for the closed-source Xerox Finite State Tools using only free
and open source tools, and run them with Apertium-compatible output
formats. The \sme{} analyser is written in the Xerox-based
\textbf{lexc} and \textbf{twol} formalisms. HFST analysers are slower
at compiling and processing than lttoolbox, but certain morphological
phenomena, especially non-concatenative phenomena \comment{e.g. \sme
  consonant gradation} are impossible---or at least very
difficult---to describe in lttoolbox. Since Northern Sámi is quite
morphologically complex, a purely lttoolbox-based analyser would be
difficult to maintain.

\section{Development}
  \label{sec:development}

This section describes how the language pair was developed.
\subsection{Resources}
We re-used several FOSS resources in creating this language pair. The
\nob{} generator came from {\tt
  apertium-nn-nb}\citep{unhammer2009rfr}, while most of the \sme{}
resources came from the Divvun and Giellatekno Sámi language
technology projects \footnote{See
  \href{http://divvun.no}{http://divvun.no} and
  \href{http://giellatekno.uit.no}{http://giellatekno.uit.no}.},
including the lexicon/morphology and disambiguator/syntactic
annotation CG. These were continually updated as the ``upstream''
versions changed.

The lexical selection CG and the transfer rules were written from
scratch. The translation lexicon was originally based on various
word-lists from Giellatekno
\href{http://giellatekno.uit.no}{http://giellatekno.uit.no}
\comment{was Vuosttaš Digisánit used?}, but expanded throughout
development.
\subsection{Analysis and derivational morphology}
The morphological analyser from N.N.\comment{Giellatekno} was not
originally made with machine translation in mind, and we had to make
several modifications, from using the Apertium tag format, to
restricting derivational morphology and removing root forms without
translations. The modifications in the language pair are all done
automatically using scripts, so that we can keep the analyser
up-to-date with the upstream version.

The upstream analyser contains many lemmas that are not in our
translational dictionary. Since these often lead to transfer errors
that can affect the surrounding context, and can suppress the choice
of forms that \textit{have} translations, we ``trim'' the analyser
down to those forms which are in the translational dictionary. To do
this, we use a script which analyses the lexc source files with the
translational dictionary, and outputs only those entries which have
translational analyses. The untrimmed source files weigh in at about
3.5 MB, trimming this down to 2.6 MB is done by a script which runs in
<10 seconds.

The original analyser defines quite a lot of rules for derivational
processes. Allowing for derivational morphology expands the coverage
of the analyser without having to add new root forms, but also makes
transfer much harder to deal with, as well as most of the time giving
very odd-sounding translations.

To give an example of the latter, `geafivuohta' is an
adjective$\rightarrow{}$noun derivation of `geafi', meaning `poor'.
Simply carrying over the information that this is an
adjective$\rightarrow{}$noun derivation into the target language
dictionary (if that dictionary also defined derivational processes)
could give us forms that sound like `poorness' or `poority' or
`poordom', whereas giving `geafivuohta' status as a real root form
would let us specify that `geafivuohta' should translate to `poverty'.

However, since \smenob is meant for gisting, where an odd-sounding
translation is more understandable than an untranslated word, we
decided to allow certain derivations. We define legal derivations by
the use of additional twol rules which simply forbid analyses
containing certain tags or tag sequences. This twol file is composed
onto the main analyser.\comment{more}

A causative verb derivation requires transfer rules that turn the
causative verb into a periphrastic construction ('let NP VERB'). If a
derivation changes the part-of-speech from verb to noun, we have to
translate the derivation into a certain verb form that looks like a
noun (e.g.~present tense of \nob verbs will most of the time look like
an actor noun)\footnote{The alternative would be to define, for each
  \sme verb, both a noun and a verb translation on the \nob side of
  the translational dictionary, but this takes away the whole point of
  increasing coverage without adding all the root forms.}




\subsection{Disambiguation}
\subsection{Lexical selection}


\subsection{Lexical transfer}

\subsection{Structural transfer}
\label{sec:structural-transfer}

\subsection{Generation}

\section{Evaluation}
\label{sec:eval}



\subsection{Word Error Rate on Post-Edited text}
\label{sec:WER}
\comment{or at least on scraped web sites ...}
\subsection{Gisting eval}
\comment{The idea here is that if the user can select the right
  alternative, she must have some comprehension of the meaning. Now,
  the sentence might have errors such that both the 'right'
  alternative and the context are wrong in the same way, but if errors
  are random enough, and the words that are translated within a
  sentence are never consistently skewed towards the same wrong
  meaning, selecting the right alternative will be a sign of
  comprehending the meaning.}



\subsection{Error analysis}

\section{Discussion and outlook}

\section*{Acknowledgements}
Development was funded by \comment{what are they called now?}
Thanks to N.N.


\nocite{zubizarreta2009amt}
